{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "2sPDGWrPM4l3",
        "outputId": "7f78d129-ffdc-4ff8-b97d-02edc1809f49"
      },
      "outputs": [],
      "source": [
        "words = open(\"words-en.txt\", \"r\")\n",
        "words_list = []\n",
        "for word in words.readlines(): \n",
        "    words_list.append(word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8860spfWQa9"
      },
      "source": [
        "# Almacenamiento sin compresión"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_38wb4tg5D8"
      },
      "source": [
        "Veamos qué longitud máxima de palabra encontramos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "E6gNuPWCWZT0"
      },
      "outputs": [],
      "source": [
        "max_word_length = 0\n",
        "max_word = \"\"\n",
        "for word in words_list:\n",
        "  if len(word) > max_word_length:\n",
        "    max_word = word\n",
        "    max_word_length = len(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "id": "tNxW49RsX8SW",
        "outputId": "acff6fb4-1823-4b9b-ac11-7f471e807841"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32\n",
            "dichlorodiphenyltrichloroethane\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(max_word_length)\n",
        "print(max_word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Si almacenáramos el vocabulario sin comprimir, necesitaríamos utilizar 32 bytes para cada término, lo que multiplicado por la cantidad de palabras de la lista, nos da el espacio total requerido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total space without compression: 11357984 bytes = 10.831817626953125 MB\n"
          ]
        }
      ],
      "source": [
        "total_space = len(words_list) * 32\n",
        "print(f\"Total space without compression: {total_space} bytes = {total_space/1024/1024} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxUofHkegqU0"
      },
      "source": [
        "# Compresión con Dictionary-as-String"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hS0G35LQQk8E",
        "outputId": "fa22756e-cce6-464a-a3a9-841684e59ded"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total characters: 3712426\n",
            "Space required: 3.540445327758789 MB\n",
            "354937\n"
          ]
        }
      ],
      "source": [
        "total_characters = 0\n",
        "word_count = 0\n",
        "for word in words_list:  \n",
        "  total_characters += len(word)\n",
        "  word_count += 1\n",
        "\n",
        "print(f\"Total characters: {total_characters}\")\n",
        "print(f\"Space required: {total_characters/1024/1024} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7ZcnjfRRNxF"
      },
      "source": [
        "Sumando la cantidad de caracteres que tienen los términos de la colección y considerando que cada caracter requiere 1 byte para ser almacenado, requeriríamos 3712426 bytes - 3.54 MB - de espacio para almacenarlo como dictionary-as-string.\n",
        "\n",
        "A su vez, debemos tener en cuenta que para saber dónde comienza y termina cada término, requerimos información adicional como un puntero al comienzo de cada uno. Con esto, dedicando 4 bytes a cada puntero, 1 por término, tenemos en total:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pointers size: 1419748 = 1.3539772033691406 MB\n",
            "Total dictionary-as-string size: 5132174 = 4.89442253112793 MB\n"
          ]
        }
      ],
      "source": [
        "pointers_size = len(words_list) * 4\n",
        "print(f\"Pointers size: {pointers_size} = {pointers_size/1024/1024} MB\")\n",
        "total_daas = total_characters + pointers_size\n",
        "print(f\"Total dictionary-as-string size: {total_daas} = {total_daas/1024/1024} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Por lo tanto, el tamaño total requerido para el almacenamiento es de 4,89 MB. Esto representa menos de la mitad utilizada por una estrategia sin compresión."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR-JR8BxX_LQ"
      },
      "source": [
        "# Límite de tamaño de palabra\n",
        "Analizando las palabras, hemos visto que la mayor tiene una longitud de 32 caracteres. Contemos cuántas ocurrencias de cada longitud de palabra hay en el archivo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ebkBeldcX6nL"
      },
      "outputs": [],
      "source": [
        "word_lengths = []\n",
        "for word in words_list:\n",
        "  word_len = len(word)\n",
        "  word_lengths.append(word_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "E2-kHO1IYlrU",
        "outputId": "7db84ba8-04f9-43d3-932e-6ac9bde22178"
      },
      "outputs": [],
      "source": [
        "%pip install matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "# Creating histogram\n",
        "fig, axs = plt.subplots(1, 1,\n",
        "                        figsize =(7, 5),\n",
        "                        tight_layout = True)\n",
        " \n",
        "axs.hist(word_lengths)\n",
        " \n",
        "# Show plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99rrxo2ZaPgk"
      },
      "outputs": [],
      "source": [
        "# importing library\n",
        "%pip install pandas\n",
        "import pandas as pd\n",
        "\n",
        "# converting list to array\n",
        "series = pd.Series(word_lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3gCi4-ra4oB",
        "outputId": "d374d39d-afb9-4b5c-d9ee-8cdbf7ce779e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    354937.000000\n",
              "mean         10.459394\n",
              "std           2.922625\n",
              "min           1.000000\n",
              "25%           8.000000\n",
              "50%          10.000000\n",
              "75%          12.000000\n",
              "max          32.000000\n",
              "dtype: float64"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "series.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtfhedssbSGI"
      },
      "source": [
        "Utilizando estadística descriptiva básica, podemos ver que la mayor parte de los términos de la colección se encuentran rondando los 10 caracteres, y que si bien son pocos los que tienen menos de 3, casi ninguno supera los 20 caracteres, salvo unas pocas excepciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PJf2P6rbw-X"
      },
      "source": [
        "Con esto en consideración, uno podría definir una longitud máxima de palabra en 20 o 21, sabiendo que son pocas las que quedarán fuera del vocabulario. Específicamente, la siguiente cantidad:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "hnJ8mZlycDzz"
      },
      "outputs": [],
      "source": [
        "greater_than_20 = series[series > 20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_w72spCcMRj",
        "outputId": "f8b304cf-261d-41bd-b042-f6323c335326"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "653"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(greater_than_20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nADPxMVecRmS"
      },
      "source": [
        "Considerando la cantidad de palabras que tenía el archivo, este valor representa el siguiente porcentaje:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNDEXyO5cZZv",
        "outputId": "8ce2e18b-43ab-47e0-acd6-dd9abc13f28f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.18397631128904565"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(greater_than_20) / len(words_list) * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnpp4NU1clvv"
      },
      "source": [
        "Es decir, solo quedarían fuera del vocabulario el 0.18% de los términos. \n",
        "\n",
        "\n",
        "Veamos cómo descendería el tamaño del vocabulario sin comprimir si tomamos un largo de 20 para cada término:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRvr9nKecw2L",
        "outputId": "747d6c52-7d66-4018-afd2-df4b53d1466e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size (term length = 20): 7085680 bytes = 6.7574310302734375 MB\n",
            "Reduction: 37.61498519455566%\n"
          ]
        }
      ],
      "source": [
        "less_or_equal_20 = series[series <= 20]\n",
        "new_size = len(less_or_equal_20)*20\n",
        "print(f\"Vocabulary size (term length = 20): {new_size} bytes = {new_size / 1024 / 1024} MB\")\n",
        "print(f\"Reduction: {(total_space - new_size)/ total_space * 100}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dp5InqoqdbYX"
      },
      "source": [
        "Vemos que la reducción es bastante significativa, dado que ganamos 12 bytes por cada término del vocabulario. Por lo tanto, sin utilizar dictionary-as-string resulta conveniente limitar el tamaño de cada término.\n",
        "\n",
        "Verifiquemos qué ocurre si quitamos estos términos pero almacenándolos con dictionary-as-string:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New vocabulary size: 3.526836395263672 MB\n",
            "Old vocabulary size: 3.540445327758789 MB\n",
            "Reduction: 0.3843847661879321%\n"
          ]
        }
      ],
      "source": [
        "size = 0\n",
        "for word in words_list:\n",
        "  word_len = len(word)\n",
        "  if word_len <= 20:\n",
        "    size += word_len\n",
        "print(f\"New vocabulary size: {size/1024/1024} MB\")\n",
        "print(f\"Old vocabulary size: {total_characters/1024/1024} MB\")\n",
        "print(f\"Reduction: {(total_characters - size)/ total_characters * 100}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Podemos observar que la reducción es muy baja, por lo que probablemente nos perjudicaríamos más quitando estos términos que manteniéndolos, siendo así capaces de responder por ellos en las queries de los usuarios."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "RI2022-TP04-09.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
